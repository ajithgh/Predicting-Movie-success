---
title: "New"
author: "Ajith Hegde"
date: "12/13/2020"
output:
  word_document: default
  html_document: default
---

# Importing File

## Reading CSV
```{r}
getwd()

movies<- read.csv("rv_bud_IMDB_All_providers.csv", header = TRUE, stringsAsFactors = TRUE)
```

## Raw Data summarisation.
```{r}
head(movies)
dim(movies)
str(movies)
```


## Installing required libraries
```{r}
library(plyr)
library(readr)
library(ggplot2)
library(GGally)
library(dplyr)
library(mlbench)
library(dplyr)
library(tidyverse)
library(dataQualityR)
library(ggplot2)
library(ROSE)
library(rpart)
library(gbm)
library(mlbench)
library(caret)
library(jsonlite)
#install.packages("rlist")
library(heatmaply)
library(naniar)
library(mice)
library(randomForest)
library(caret)
library(fastDummies)
library(rlist)

```

## Checking Raw Data quality
 + Script loads a file and produces a data quality report for
 + numerical variables: "dq_num.csv"
 + categorical variables: "dq_cat.cs"
```{r}
checkDataQuality(data = moviessamp, 
                 out.file.num ="dq_num.csv", 
                 out.file.cat= "dq_cat.csv")
dq_num<-read.csv("dq_num.csv")
dq_cat<-read.csv("dq_cat.csv")
dq_num
dq_cat
```

# Feature Engineering before Imputation

## Converting 0s to NAs
```{r}
movies$revenue[movies$revenue == 0] = NA
movies$budget[movies$budget == 0] = NA
movies$revenue[((movies$budget > 100000) && (movies$revenue < 1000))] = NA
movies$budget[movies$revenue > 100000 & movies$budget < 1000] = NA
movies$runtime[movies$runtime == 0] = NA
movies$popularity[movies$popularity == 0] = NA
movies$vote_average[movies$vote_average == 0] = NA
movies$review_count[movies$review_count == 0] = NA
movies$cast_size[movies$cast_size == 0] = NA
movies$crew_size[movies$crew_size == 0] = NA
movies$Imdb_vote_count[movies$Imdb_vote_count == ""] = 0
movies$vote_count[movies$vote_count == ""] = 0
```

## Extracting Release Date
```{r}
#colnames(movies)
#str(movies)
movies$release_d = as.Date(movies$release_date, "%m/%d/%Y")
movies$release_year = format(as.POSIXct(strptime(movies$release_d,"%Y-%m-%d", tz="")) ,format = "%Y")
movies$release_month = format(as.POSIXct(strptime(movies$release_d,"%Y-%m-%d", tz="")) ,format = "%m")
#view(movies)
movies$release_month = as.integer(movies$release_month)
```

## Holiay month release
```{r}
#str(movies)
movies$holidaymonth = ifelse((movies$release_month == 12 |movies$release_month == 06 | movies$release_month == 07) , 1, 0)
table(movies$holidaymonth)
```

## Converting text features to Binomial and then subsetting it.
+ tagline
+ belongs to collection
```{r}
movies$taglinepresent = ifelse(movies$tagline == "", 0, 1)
table(movies$taglinepresent)
movies$collectionyes = ifelse(movies$belongs_to_collection == "", 0, 1)
table(movies$collectionyes)
movies2 = subset(movies, select = -c(tagline))
#str(movies2)
```

## Converting Numerical feature for provider
```{r}
#str(movies2$all_uniq_providers)
#movies2$providenos = str_count(movies2$all_uniq_providers, pattern = ",")
#movies2$providenos = ifelse(movies2$all_uniq_providers == "",0,(str_count(movies2$all_uniq_providers, pattern = ",") + 1))
#view(movies2)
```



#Data Imputation

## Sample Method using MICE Package for numerical
```{r}
#colnames(movies2)
samp = subset(movies2, select = c(revenue, budget, runtime, popularity, vote_average, vote_count, review_count, cast_size, crew_size, release_month, Imdb_Rating, Imdb_vote_count))

# Using MICE, missing values are imputed through a linear regression prediction based on the existing values

iv_samp = mice(data = samp, m = 5, method = "sample", maxit = 5)
num_c_samp = complete(iv_samp, 1)
view(num_c_samp)

moviessamp = subset(movies2, select = -c(revenue, budget, runtime, popularity, vote_average, vote_count, review_count, cast_size, crew_size, release_month, Imdb_Rating, Imdb_vote_count))
#str(moviessamp)
moviessamp = cbind(moviessamp, num_c_samp)
colnames(moviessamp)
sum(is.na(moviessamp))
#View(moviessamp)
```


## Create New Features based on imputation
+ profit_factor
+ cast_crew_ratio
+ Target
```{r}
moviessamp$profit_factor = ((moviessamp$revenue - moviessamp$budget) / moviessamp$budget)*100
moviessamp$cast_crew_ratio = moviessamp$cast_size / movies$crew_size
#movies$targetprofit = ifelse(movies$profit_factor < 1, 0, ifelse(movies$profit_factor >= 1 & movies$profit_factor < 2, 1, 2))
moviessamp$Target = ifelse(moviessamp$profit_factor < 1, 0, 1)
table(moviessamp$Target)
```

## Feature based on Revenue and other columns
+ movie directed by a high paid director?
+ most profitable production companies
+ avg. revenue of Collection
+ Competition during Release
+ most profitable genre
+ Avg revenue by crew size
+ Avg Revenue by cast Size
+ Cost per Capita
```{r}
# movie directed by a high paid director? | 0 or 1
mostpopulardirectors<-arrange(aggregate(moviessamp$revenue, by=list(moviessamp$director), FUN="mean"), desc(x))
top10directors<-top_n(mostpopulardirectors,10)
top10directors
top10directors<-top10directors$Group.1

moviessamp$directedByAPopular<-ifelse(moviessamp$director %in% top10directors, 1, 0)
table(moviessamp$directedByAPopular)

# most profitable production companies | 0 or 1
mostprofitableProducComp<-arrange(aggregate(moviessamp$revenue, by=list(moviessamp$production_companies), FUN= "mean"), desc(x))
mostprofitableProducComp<-top_n(mostprofitableProducComp,20)
mostprofitableProducComp<-mostprofitableProducComp$Group.1

moviessamp$belongs_to_topProfitProdComp<-if_else(moviessamp$production_companies %in% mostprofitableProducComp,1, 0)
table(moviessamp$belongs_to_topProfitProdComp)


## Feature 3 average revenue collection movie | number
avg_collection_movies<-arrange(aggregate(moviessamp$revenue, by=list(moviessamp$belongs_to_collection), FUN= "mean"), desc(x))
avg_collection_movies<-rename(avg_collection_movies, "belongs_to_collection"="Group.1")
avg_collection_movies<-rename(avg_collection_movies, "avg_coll_revenue"="x")
avg_collection_movies
moviessamp<-inner_join(moviessamp,avg_collection_movies, by="belongs_to_collection" )
#str(moviessamp)


# Feature 4 competition during release | Number  
moviessamp$release_week<-strftime(moviessamp$release_d, format = "%V")
releasedMoviesByWeek<-aggregate(moviessamp$id,by=list(moviessamp$release_week), FUN= "length")
releasedMoviesByWeek<-rename(releasedMoviesByWeek, "release_week"="Group.1")
releasedMoviesByWeek<-rename(releasedMoviesByWeek, "movies_released_same_week"="x")
releasedMoviesByWeek
moviessamp<-inner_join(moviessamp,releasedMoviesByWeek, by="release_week" )


## Feature 5 most profitable genres | 1 or 0
mostprofitableGenres<-arrange(aggregate(moviessamp$revenue,by=list(moviessamp$genre), FUN="mean"), desc(x))
mostprofitableGenres<-top_n(mostprofitableGenres,20)
mostprofitableGenres<-mostprofitableGenres$Group.1
mostprofitableGenres
moviessamp$belongs_to_topProfitGenres<-if_else(moviessamp$genre %in% mostprofitableGenres,1, 0)


## Feature 6 : Avg revenue by crew size | number
avg_rev_by_crew_size<-arrange(aggregate(moviessamp$revenue,by=list(moviessamp$crew_size), FUN="mean"), desc(x))
avg_rev_by_crew_size<-rename(avg_rev_by_crew_size, "crew_size"="Group.1")
avg_rev_by_crew_size<-rename(avg_rev_by_crew_size, "avg_rev_by_crew_size"="x")
avg_rev_by_crew_size
moviessamp<-inner_join(moviessamp,avg_rev_by_crew_size, by="crew_size" )


## Feature 7:  Avg revenue by cast size

avg_rev_by_cast_size<-arrange(aggregate(moviessamp$revenue,by=list(moviessamp$cast_size), FUN="mean"), desc(x))
avg_rev_by_cast_size<-rename(avg_rev_by_cast_size, "cast_size"="Group.1")
avg_rev_by_cast_size<-rename(avg_rev_by_cast_size, "avg_rev_by_cast_size"="x")
avg_rev_by_cast_size
moviessamp<-inner_join(moviessamp,avg_rev_by_cast_size, by="cast_size" )


#Features 8:  Cost per Capita
moviessamp$costPerCapita<-moviessamp$budget/(moviessamp$crew_size+movies$cast_size)
str(moviessamp)


## Feature 9 budget per genre | number
budgetpergenre<-arrange(aggregate(moviessamp$budget ,by=list(moviessamp$genre), FUN="mean"), desc(x))
budgetpergenre<-rename(budgetpergenre, "genre"="Group.1")
budgetpergenre<-rename(budgetpergenre, "avg_budget_per_genre"="x") 
budgetpergenre
moviessamp<-inner_join(moviessamp,budgetpergenre, by="genre")


```



## Sample Method using MICE Package for cast-crew-ratio and holdidaymonths
```{r}

samp2 = subset(moviessamp, select = c(cast_crew_ratio, holidaymonth, costPerCapita))

# Using MICE, missing values are imputed through a linear regression prediction based on the existing values

iv_samp2 = mice(data = samp2, m = 5, method = "sample", maxit = 5)
num_c_samp2 = complete(iv_samp2, 1)

moviessamp2 = subset(moviessamp, select = -c(cast_crew_ratio, holidaymonth, costPerCapita))
moviessamp2 = cbind(moviessamp2, num_c_samp2)
sum(is.na(moviessamp2))
#str(moviessamp2)
```

## Output Non-Zero Imputed File
```{r}
#write.csv(moviessamp2,"Imputed file SunNight.csv")
```


## Removing Unwanted columns and converting to factors
```{r}
df = subset(moviessamp2, select = -c(X, original_title, backdrop_path, homepage, imdb_id, id, poster_path, release_date, status, title, video, keywords, director, production_companies, release_year, release_d, belongs_to_collection, rent_options, buy_options, flatrate_options, release_week))

colnames(df)
df$release_month = as.factor(df$release_month) 
str(df)
```

# Dummify Factors

## Dummify Factor Columns
```{r}

dummy = dummy_cols(
  df,
  select_columns = c(
    "original_language",
    "adult",
    "genre",
    "spoken_languages",
    "production_countries",
    "release_month",
    "all_uniq_providers"
  ),
  split = ",",
  remove_selected_columns = TRUE
)

dim(dummy)
sum(is.na(dummy))

```

----

#### Improve the naming of attributes
```{r}
library(stringr)

names(dummy)<-str_replace_all(names(dummy)," ","_")
names(dummy)<-str_replace_all(names(dummy),"_/_","_")
names(dummy)<-str_replace_all(names(dummy),",_","_")
names(dummy)<-str_replace_all(names(dummy),":_","_")
names(dummy)<-str_replace_all(names(dummy),"/","_")
names(dummy)<-str_replace_all(names(dummy),"-","_")

#names(dummy)
```



# Initalising Y and X
```{r}
# library(randomForest)
# library(caret)

outcomeName <- 'Target'
predictorNames <- names(dummy)[names(dummy) != outcomeName]

finaldata = subset(dummy, select = -c(profit_factor, revenue ))
```


## RF Model for feature selection 
```{r}
set.seed(103)

split = 0.8

# After cleaning the data, predictions can now be made on the feature importance
# First thing we do is create testing and training sets

index = createDataPartition(finaldata$Target, p= split, list=FALSE)

train_data = finaldata[index, ]
test_data  = finaldata[-index, ]


train_data$Target = as.factor(train_data$Target)


# In order to trim down the number of features to be used, a Random Forest model is used with bagging to find the most important ones using the randomForest model with 300 trees and 9 features per bag 9 features was chosen as it is close to the square root of the feature size.


rfModel = randomForest(Target ~ ., 
                       data = train_data,
                       ntree = 300,
                       mtry = 9,
                       replace = T)



varImpPlot(rfModel)
#importance(rfModel)

```




## Top 50 Important features from RF
```{r}
var_importance = cbind(names(subset(finaldata, select = -c(Target))), varImp(rfModel))
var_importance = arrange(var_importance, desc(Overall))

var_importance$Features = var_importance$`names(subset(finaldata, select = -c(Target)))`

col_names = as.data.frame(var_importance$Features[1:50])

names(df) %in% col_names$`var_importance$Features[1:50]`

important_data = subset(finaldata, select = names(finaldata) %in% col_names$`var_importance$Features[1:50]`)
important_data$Target = finaldata$Target
```

Once we have a dataset of only 25 of the most important features we can balance the dataset to an 50:50 ratio using the ROSE package

## ROSE Sampling
```{r}
important_data_balanced = ovun.sample(Target~., data = important_data, method = "both",  p=0.6)$data
prop.table(table(important_data_balanced$Target))

train_data = important_data_balanced[index, ]
test_data  = important_data_balanced[-index, ]
train_data$Target = as.factor(train_data$Target)
```


Once we have the most important features, and a balanced dataset,  the first model to run is Logistic Regression using lgm

# Logistic Regression

## Predicting using GLM Model 
```{r}
logModel = glm(Target ~ ., data = train_data, family = "binomial", maxit = 100)

predictions_log = as.data.frame(as.factor(ifelse(predict(logModel, 
                                                         test_data, 
                                                         type = "response")>0.5, 1, 0)))

```

Using caret and ROSE, a confusion matrix and ROC curve are created respectively

## Confusion Matrix for above glm model
```{r}
test_data$Target = as.factor(test_data$Target)

confusionMatrix(predictions_log$`as.factor(ifelse(predict(logModel, test_data, type = "response") > 0.5, 1, 0))`, 
                test_data$Target)

roc.curve(test_data$Target, 
          predictions_log$`as.factor(ifelse(predict(logModel, test_data, type = "response") > 0.5, 1, 0))`,
          plotit = T,
          main = "Logistic Regression Model")
```

## Predicting using RF Model
The second model to run is a repeat of the one used when selecting features
```{r}
rfModel2 = randomForest(Target ~ ., 
                       data = train_data,
                       ntree = 300, 
                       mtry = 9, 
                       replace = T) 
predictions_rf2 = as.data.frame(predict(rfModel2, 
                                       test_data, 
                                       type = "response"))
```


```{r}
confusionMatrix(predictions_rf2$`predict(rfModel2, test_data, type = "response")`,
                test_data$Target)

roc.curve(test_data$Target, 
          predictions_rf2$`predict(rfModel2, test_data, type = "response")`,
          plotit = T,
          main = "ROC Curve for Random Forest w/ Bagging Model")
```

# Gabriela's Feature Engineering

## Feature 1
```{r}

```

## Feature 2
```{r}

```

